import argparse 
import json
import pandas as pd
import statsmodels.stats.multitest as ssm

"""
This script combine all json file generated by the HyPhy aBSREL model and calculate a mutlitesting correction
The output is a file combing the tests for all genes 

command:

    python combine_pos_sell_info_absrel.py --files_possel < list of json file from HyPhy> --files_sat_subst <list of file for sat subst> --prefix_out <prefix for ouput file>

"""



def map_confident_to_all(confident:str)-> list:
    """
    """
    regions = []
    with open(confident) as file_handler:
        for line in file_handler:
            tab = line.split()
            regions.append([int(tab[0]), int(tab[-1])])
    
    mapping =[]
    for region in regions:
        i = region[0]
        while i < region[1]:
            mapping.append(i)
            i = i + 1
    return mapping

def convert_position(position:str, mapping:list)->str:
    """
    """
    if position == "":
        return ""
    new_pos = []
    tab_pos = position.split("|")
    for elem in tab_pos:
        tab = elem.split(":")
        pos = mapping[int(tab[0])]
        new_pos.append(f"{pos}:{tab[1]}")
    return "|".join(new_pos)


def map_inputs(pos_sel:dict, sat_substs:dict, confident:dict)-> list:
    """ 
    This function map together the possel and substitution saturation dictionaries

    :param pos_sel: dictionary of with data from calculate_codeml_pval.py 
    :param sat_substs: dicitonary with substritution fo saturation
    :return: list with all the data together for each orthogroup
    """
   # id_conf =  conf.split("/")[-1].split(".confident")[0]
    result =[]
    for id, val in pos_sel.items():
        values = val
        
        #convert position to original alignment
        positions = values[-1]
        map_conf = map_confident_to_all(confident[id])
        values[-1] = convert_position(positions, map_conf)

        #add subst saturation data 
        if id in sat_substs:
            values = values + sat_substs[id ][1:]
        else:
            values = values + ["NA","NA","NA","1.0"]
        
        #append the row tot he matrix
        result.append(values)
    return result


def fetch_pos_sel_info(tsv_file:str, sat_subst:str)->list:
    """
    Retrieve the positive selction information fomr the json file

    :param tsv_file: tsv file from calculate_codeml_pval.py 
    :param sat_subst: file from test_saturation_substitution.py
    :return: the list of element in the line.
    """
    lst_val = []
    with open(sat_subst) as sat_subst_handler:
        for line in sat_subst_handler:
            if "exp_entrop" in line:
                continue
            lst_val = line.split()
            break

    with open(tsv_file) as file_handler:
        file_contents = file_handler.readlines()
    
    parsed_tsv = file_contents[1].split()
    values = []
    for val in parsed_tsv[1:]:
        values.append(float(val))
    result =  parsed_tsv[0:1] + values + [float(lst_val[-1]), float(lst_val[1]), float(lst_val[0])]
    return result

def _create_data_frame(pos_sel_branches:list)->object:
    """
    This function create a dataframe fromt the matrix of postive selection informaton associated
    to each branch/species in the input dictionary.

    :param pos_sel_branches: dictionary storing the information matrix for each species/branch tested
    :return: an empy data frame with the column intialised.
    """

    df = pd.DataFrame(pos_sel_branches,  columns =  ["gene_id", "lrt", "pval_possel", "alt_w_0", 
                                                     "alt_w_1", "alt_w_2a", "alt_w_2b", "null_w_0", 
                                                     "null_w_1", "null_w_2a", "null_w_2b", "position",
                                                     "exp_entropy","obs_entropy", "t_stat", "pval_no_sat"])
    df.astype({"lrt":float, "pval_possel":float, "alt_w_0":float, 
                "alt_w_1":float, "alt_w_2a":float, "alt_w_2b":float, "null_w_0":float, 
                "null_w_1":float, "null_w_2a":float, "null_w_2b":float, "exp_entropy":float,
                "obs_entropy":float, "t_stat":float, "pval_no_sat":float})
    return df

def multitetesting_correction(pos_sel_df:object, method:str="fdr_bh")->dict:
    """
    This function performed a multitesting correction
    
    :param pos_sel_df: data frame with positive slection informaiton for each gene
    :param method: the method to be used for multitesting correction
    :return: dictionary of that store the postive selction data for each branch/species
             including the adjusted pvalues.
    """
    pval = pos_sel_df["pval_possel"]
    
    rej, pval_adj, alphasidak, alphacBonf = ssm.multipletests(pd.to_numeric(pval), method=method)
    pos_sel_df["pval_adj_possel"] = pval_adj
    return pos_sel_df

def read_comb_possel(comb_file:str)->dict:
    """
    This function read the combined file of possitive selction and create a ortho_id<->data dictionary

    :param com_file: the path tot he file that combine all the positive selction data
    :return : diction nary where the key is the orthogroup and the values the data associated to 
              the positive secltion analysis.    
    """
    
    result = {}
    with open(comb_file) as file_handler:
        for line_file in file_handler:
                file = line_file.replace("[","").replace("]","").replace(",","").replace("\n", "")
                with open(file) as file_gene:
                    for line in file_gene:
                        if "gene_id" in line:
                            continue
                        tab = line.replace("\n","").split("\t")
                        result[tab[0]] = tab
    return result

def read_comb_sat(comb_file:str)->dict:
    """
    This function read the combined file of combined entropy and create a ortho_id<->data dictionary

    :param com_file: the path tot he file that combine all the saturation analysis data
    :return : diction nary where the key is the orthogroup and the values the data associated to 
              the saturation analysis analysis.    
    """
    result = {}
    with open(comb_file) as file_handler:
        for line_file in file_handler:
                file = line_file.replace("[","").replace("]","").replace(",","").replace("\n", "")
                with open(file) as file_gene:
                    for line in file_gene:
                        if "exp_entrop" in line:
                            continue
                        tab = line.replace("\n","").split("\t")
                        result[tab[0]] = tab
    return result

def read_comb_conf(conf_file:str)->dict:
    """
    """
    result = {}
    with open(conf_file) as file_handler:
        for line in file_handler:
            file = line.replace("[","").replace("]","").replace(",","").replace("\n", "")
            id_conf =  file.split("/")[-1].split(".confident")[0]
            result[id_conf] = file
    return result





def convert_origin_coordinate(df:object)->object:
    pass


def main(file_possel:str, file_sat_subst:str, confident_file:str, pref_out:str)->None:
    """
    The main function of the script

    :param files: string that list all tsv files to be parsed separated by a white space
    :param file_sat_subst: the list fo file with substitution saturation info
    :param pref_out: prefix used for the file name
    """
    dico_possel = read_comb_possel(file_possel)
    dico_sat = read_comb_sat(file_sat_subst)
    dico_conf = read_comb_conf(confident_file)
    #tsvs = files.split()
    #subst_sats = file_sat_subst.split()
 
    pos_sel_vals = map_inputs(dico_possel, dico_sat)

    #converting array to pandas df
    pos_sel_val_df = _create_data_frame(pos_sel_vals)

    # mutli testtin correction
    pos_sel_val_mlt = multitetesting_correction(pos_sel_val_df)

    pos_sel_val_mlt_ori= convert_origin_coordinate(pos_sel_val_mlt)
    
   
    #save the file per branche
    file_name = f"{pref_out}.possel"
    pos_sel_val_mlt.to_csv(file_name, sep="\t")


########################################################################################
########### Main script
########################################################################################

parser = argparse.ArgumentParser(description='Script formating the data to be handle by the positvie selction pipeline')
parser.add_argument('--files_possel',type=str, help='list of tsv file to integrate')
parser.add_argument('--files_sat_subst',type=str, help='list of files for saturation_substitution')
parser.add_argument('--confident', type=str, help='confident region file. ')
parser.add_argument('--prefix_out', type=str, help='prefix for outfiles')

args = parser.parse_args()
main(args.files_possel, args.files_sat_subst, args.confident, args.prefix_out)

